code: vpsubd (%rbx), %ymm2, %ymm1

  maybe read:      { %rbx %ymm2 }
  must read:       { %rbx %ymm2 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx2 }

vpsubd (%rbx), %ymm2, %ymm1: Hindex0(10)
vpsubd (%rbx), %ymm2, %ymm1: Hindex0(10)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vmaxps %ymm3, %ymm11, %ymm1: Hindex0(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_byte_5_of_ymm1_to_r9b: Hindex8(9)
callq .move_064_128_r8_r9_xmm2: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm8_xmm9_xmm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vrcpps %ymm1, %ymm10: Hindex0(9)
callq .move_128_256_xmm10_xmm11_ymm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vrcpps %ymm1, %ymm10: Hindex0(9)
callq .move_128_256_xmm10_xmm11_ymm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_64_128_xmm8_xmm9_xmm1: Hindex8(9)
callq .move_256_128_ymm3_xmm10_xmm11: Hindex8(9)
callq .move_256_128_ymm2_xmm12_xmm13: Hindex8(9)
callq .move_128_64_xmm1_xmm12_xmm13: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movq %r10, %rbx: Hindex5(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
movswq %bx, %r10: Hindex5(9)
movslq %ebx, %rbx: Hindex5(9)
callq .move_032_016_ecx_r8w_r9w: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movq %r10, %rcx: Hindex5(9)
callq .move_016_032_r8w_r9w_ebx: Hindex8(9)
xorq %rcx, %rbx: Hindex1(9)
callq .set_szp_for_ebx: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
vmaxps %ymm15, %ymm15, %ymm1: Hindex0(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_256_128_ymm2_xmm8_xmm9: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_256_128_ymm2_xmm8_xmm9: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vmaxps %ymm3, %ymm11, %ymm1: Hindex0(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_byte_5_of_ymm1_to_r9b: Hindex8(9)
callq .move_064_128_r8_r9_xmm2: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm8_xmm9_xmm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vrcpps %ymm1, %ymm10: Hindex0(9)
callq .move_128_256_xmm10_xmm11_ymm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vrcpps %ymm1, %ymm10: Hindex0(9)
callq .move_128_256_xmm10_xmm11_ymm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_64_128_xmm8_xmm9_xmm1: Hindex8(9)
callq .move_256_128_ymm3_xmm10_xmm11: Hindex8(9)
callq .move_256_128_ymm2_xmm12_xmm13: Hindex8(9)
callq .move_128_64_xmm1_xmm12_xmm13: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movq %r10, %rbx: Hindex5(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r10, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
movswq %bx, %r10: Hindex5(9)
movslq %ebx, %rbx: Hindex5(9)
callq .move_032_016_ecx_r8w_r9w: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movq %r10, %rcx: Hindex5(9)
callq .move_016_032_r8w_r9w_ebx: Hindex8(9)
xorq %rcx, %rbx: Hindex1(9)
callq .set_szp_for_ebx: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_256_128_ymm2_xmm12_xmm13: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movq %r10, %rbx: Hindex5(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r10_r11: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
movq %r11, %r12: Hindex5(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_256_128_ymm3_xmm8_xmm9: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
xorq %r8, %r12: Hindex1(9)
xorq %r9, %r13: Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r10_r11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
orq %r9, %r11: Hindex1(9)
orq %r8, %r10: Hindex1(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r12_r13: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
xorq %r13, %r9: Hindex1(9)
xorq %r12, %r8: Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
vcvttps2dq %ymm8, %ymm1: Hindex0(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_cf: Hindex8(9)
movq $0xfffffffffffffffe, %rdx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
callq .read_zf_into_rcx: Hindex8(9)
adcb %cl, %bl: Hindex2(9)
xorq %rdx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .read_cf_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r8d_r9d: Hindex8(9)
callq .move_r8b_to_byte_5_of_rbx: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
movq $0xffffffffffffffff, %rsi: Hindex5(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
callq .read_cf_into_rbx: Hindex8(9)
adcw %bx, %ax: Hindex2(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %bx: Hindex2(9)
callq .set_szp_for_bx: Hindex8(9)
movswq %si, %rbx: Hindex5(9)
movb %cl, %bh: Hindex5(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
callq .set_szp_for_bl: Hindex8(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
callq .clear_cf: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movsbq %r15b, %rcx: Hindex5(9)
adcb %cl, %r13b: Hindex2(9)
movslq %r13d, %rbx: Hindex5(9)
movb %dl, %ah: Hindex5(9)
movq $0x4, %rdi: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcb %al, %al: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %r8, %r8: Hindex1(9)
movq $0x40, %rbx: Hindex5(9)
movb %ah, %bl: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
callq .read_cf_into_rcx: Hindex8(9)
movb %cl, %ah: Hindex5(9)
movswq %bx, %rdx: Hindex5(9)
xorq %rbp, %rdx: Hindex1(9)
movslq %edx, %rbx: Hindex5(9)
callq .set_szp_for_bl: Hindex8(9)
xorq %rax, %rax: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
adcw %cx, %ax: Hindex2(9)
popcntq %rax, %rbx: Hindex1(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
xorq %rcx, %rcx: Hindex1(9)
callq .read_sf_into_rbx: Hindex8(9)
movb %ah, %bl: Hindex5(9)
movq $0x0, %rbx: Hindex5(9)
xorq %rax, %rax: Hindex1(9)
adcb %al, %al: Hindex2(9)
movsbq %cl, %rdi: Hindex5(9)
adcb %dil, %bl: Hindex2(9)
movslq %r12d, %rdx: Hindex5(9)
callq .move_016_008_dx_r8b_r9b: Hindex8(9)
callq .set_of: Hindex8(9)
callq .read_of_into_rbx: Hindex8(9)
callq .move_064_032_rbx_r10d_r11d: Hindex8(9)
movsbq %cl, %r10: Hindex5(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movb %dl, %ah: Hindex5(9)
callq .move_r9b_to_byte_6_of_rbx: Hindex8(9)
popcntq %rdx, %r9: Hindex1(9)
adcb %sil, %bl: Hindex2(9)
movslq %ebx, %rbx: Hindex5(9)
adcl %ebx, %ebx: Hindex2(9)
adcb %bl, %bl: Hindex2(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm10_xmm11: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_64_xmm2_xmm12_xmm13: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
callq .move_128_064_xmm1_r10_r11: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
vzeroall : Hindex1(9)
movslq %r8d, %r9: Hindex5(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_64_xmm1_xmm8_xmm9: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_64_xmm1_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_64_128_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d: Hindex8(9)
callq .move_032_064_r10d_r11d_rbx: Hindex8(9)
movq %r10, %rbx: Hindex5(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r10_r11: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
movq %r11, %r12: Hindex5(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm1_r8_r9: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_016_008_bx_r10b_r11b: Hindex8(9)
callq .move_016_008_cx_r8b_r9b: Hindex8(9)
callq .move_008_016_r10b_r11b_cx: Hindex8(9)
callq .move_008_016_r8b_r9b_bx: Hindex8(9)
orq %rbx, %rbx: Hindex1(9)
adcq %rcx, %rbx: Hindex2(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
vfmsub132ps %ymm0, %ymm4, %ymm1: Hindex1(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
vrcpps %ymm1, %ymm10: Hindex0(9)
callq .move_128_256_xmm10_xmm11_ymm1: Hindex8(9)
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r10_r11_xmm3: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1: Hindex8(9)
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall : Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_256_xmm12_xmm13_ymm1: Hindex8(9)
Formula:

%ymm1  : (let ((a!1 (concat #b0
                   (bvxor (concat ((_ extract 255 224) TMP_BV_256_0)
                                  ((_ extract 255 224) %ymm2))
                          #xffffffffffffffff)))
      (a!4 (concat #b0
                   (bvxor (concat ((_ extract 223 192) TMP_BV_256_1)
                                  ((_ extract 223 192) %ymm2))
                          #xffffffffffffffff)))
      (a!7 (concat #b0
                   (bvxor (concat ((_ extract 191 160) TMP_BV_256_2)
                                  ((_ extract 191 160) %ymm2))
                          #xffffffffffffffff)))
      (a!10 (concat #b0
                    (bvxor (concat ((_ extract 159 128) TMP_BV_256_3)
                                   ((_ extract 159 128) %ymm2))
                           #xffffffffffffffff)))
      (a!14 (concat #b0
                    (bvxor (concat ((_ extract 127 96) TMP_BV_256_4)
                                   ((_ extract 127 96) %ymm2))
                           #xffffffffffffffff)))
      (a!17 (concat #b0
                    (bvxor (concat ((_ extract 95 64) TMP_BV_256_5)
                                   ((_ extract 95 64) %ymm2))
                           #xffffffffffffffff)))
      (a!20 (concat #b0
                    (bvxor (concat ((_ extract 63 32) TMP_BV_256_6)
                                   ((_ extract 63 32) %ymm2))
                           #xffffffffffffffff)))
      (a!23 (concat #b0
                    (bvxor (concat ((_ extract 31 0) TMP_BV_256_7)
                                   ((_ extract 31 0) %ymm2))
                           #xffffffffffffffff))))
(let ((a!2 (bvadd a!1
                  #b00000000000000000000000000000000000000000000000000000000000000001
                  (concat #b0
                          (concat ((_ extract 255 224) %ymm2)
                                  ((_ extract 255 224) %ymm2)))))
      (a!5 (bvadd a!4
                  #b00000000000000000000000000000000000000000000000000000000000000001
                  (concat #b0
                          (concat ((_ extract 223 192) %ymm2)
                                  ((_ extract 223 192) %ymm2)))))
      (a!8 (bvadd a!7
                  #b00000000000000000000000000000000000000000000000000000000000000001
                  (concat #b0
                          (concat ((_ extract 191 160) %ymm2)
                                  ((_ extract 191 160) %ymm2)))))
      (a!11 (bvadd a!10
                   #b00000000000000000000000000000000000000000000000000000000000000001
                   (concat #b0
                           (concat ((_ extract 159 128) %ymm2)
                                   ((_ extract 159 128) %ymm2)))))
      (a!15 (bvadd a!14
                   #b00000000000000000000000000000000000000000000000000000000000000001
                   (concat #b0
                           (concat ((_ extract 127 96) %ymm2)
                                   ((_ extract 127 96) %ymm2)))))
      (a!18 (bvadd a!17
                   #b00000000000000000000000000000000000000000000000000000000000000001
                   (concat #b0
                           (concat ((_ extract 95 64) %ymm2)
                                   ((_ extract 95 64) %ymm2)))))
      (a!21 (bvadd a!20
                   #b00000000000000000000000000000000000000000000000000000000000000001
                   (concat #b0
                           (concat ((_ extract 63 32) %ymm2)
                                   ((_ extract 63 32) %ymm2)))))
      (a!24 (bvadd a!23
                   #b00000000000000000000000000000000000000000000000000000000000000001
                   (concat #b0
                           (concat ((_ extract 31 0) %ymm2)
                                   ((_ extract 31 0) %ymm2))))))
(let ((a!3 (bvadd (concat #b0 (concat #x00000000 ((_ extract 63 32) a!2)))
                  (concat #b0 (concat #x00000000 ((_ extract 31 0) a!2)))))
      (a!6 (bvadd (concat #b0 ((_ extract 63 0) a!5))
                  (concat #b0 (concat #x00000000 ((_ extract 63 32) a!5)))))
      (a!9 (bvadd (concat #b0
                          (concat ((_ extract 63 32) a!8)
                                  ((_ extract 63 32) a!8)))
                  (concat #b0 ((_ extract 63 0) a!8))))
      (a!12 (bvadd (concat #b0
                           (concat ((_ extract 63 32) a!11)
                                   ((_ extract 63 32) a!11)))
                   (concat #b0 ((_ extract 63 0) a!11))))
      (a!16 (bvadd (concat #b0 (concat #x00000000 ((_ extract 63 32) a!15)))
                   (concat #b0 (concat #x00000000 ((_ extract 31 0) a!15)))))
      (a!19 (bvadd (concat #b0 ((_ extract 63 0) a!18))
                   (concat #b0 (concat #x00000000 ((_ extract 63 32) a!18)))))
      (a!22 (bvadd (concat #b0
                           (concat ((_ extract 63 32) a!21)
                                   ((_ extract 63 32) a!21)))
                   (concat #b0 ((_ extract 63 0) a!21))))
      (a!25 (bvadd (concat #b0
                           (concat ((_ extract 63 32) a!24)
                                   ((_ extract 63 32) a!24)))
                   (concat #b0 ((_ extract 63 0) a!24)))))
(let ((a!13 (concat (concat (concat ((_ extract 31 0) a!3)
                                    ((_ extract 31 0) a!6))
                            ((_ extract 31 0) a!9))
                    ((_ extract 31 0) a!12)))
      (a!26 (concat (concat (concat ((_ extract 31 0) a!16)
                                    ((_ extract 31 0) a!19))
                            ((_ extract 31 0) a!22))
                    ((_ extract 31 0) a!25))))
  (concat a!13 a!26)))))

Information about memory reads:
  Value TMP_BV_256_0 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_1 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_2 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_3 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_4 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_5 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_6 (32 bytes)
    was read at address %rbx.
  Value TMP_BV_256_7 (32 bytes)
    was read at address %rbx.

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv
