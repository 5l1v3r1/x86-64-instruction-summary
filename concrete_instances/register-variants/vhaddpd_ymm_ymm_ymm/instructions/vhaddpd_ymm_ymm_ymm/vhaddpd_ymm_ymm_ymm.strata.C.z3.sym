code: vhaddpd %ymm3, %ymm2, %ymm1

  maybe read:      { %ymm2 %ymm3 }
  must read:       { %ymm2 %ymm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx }

vhaddpd %ymm3, %ymm2, %ymm1: Hindex8(9)
vhaddpd %ymm3, %ymm2, %ymm1: Hindex8(9)
callq .move_256_128_ymm3_xmm12_xmm13: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
vzeroall: Hindex1(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_256_128_ymm2_xmm8_xmm9: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall: Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r10_r11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
movq %r9, %r10: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_064_128_r8_r9_xmm3: Hindex8(9)
vaddpd %ymm3, %ymm1, %ymm1: Hindex0(9)
vminpd %ymm9, %ymm9, %ymm12: Hindex0(9)
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r12_r13: Hindex8(9)
callq .move_064_128_r12_r13_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
vzeroall: Hindex1(9)
movq %r8, %r11: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
callq .move_064_128_r8_r9_xmm1: Hindex8(9)
callq .move_128_064_xmm3_r10_r11: Hindex8(9)
callq .move_128_064_xmm2_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
movq %r9, %r10: Hindex5(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_128_064_xmm2_r10_r11: Hindex8(9)
callq .move_128_064_xmm3_r8_r9: Hindex8(9)
vzeroall: Hindex1(9)
callq .move_064_128_r10_r11_xmm1: Hindex8(9)
callq .move_064_128_r8_r9_xmm3: Hindex8(9)
vaddpd %ymm3, %ymm1, %ymm1: Hindex0(9)
vminpd %ymm9, %ymm9, %ymm12: Hindex0(9)
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7: Hindex8(9)
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1: Hindex8(9)
callq .move_128_256_xmm8_xmm9_ymm1: Hindex8(9)
Formula:

%ymm1  : (concat (concat (add_double ((_ extract 191 128) %ymm3)
                            ((_ extract 255 192) %ymm3))
                (add_double ((_ extract 191 128) %ymm2)
                            ((_ extract 255 192) %ymm2)))
        (concat (add_double ((_ extract 63 0) %ymm3) ((_ extract 127 64) %ymm3))
                (add_double ((_ extract 63 0) %ymm2) ((_ extract 127 64) %ymm2))))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv
